{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YOWuB66P0xyd"
      },
      "source": [
        "# VisualCLA Inference & Deployment\n",
        "\n",
        "è¯¥notebookå±•ç¤ºäº†ä»ç¯å¢ƒå‡†å¤‡ã€æ¨¡å‹åˆå¹¶åˆ°æ¨ç†ä»¥åŠGradioéƒ¨ç½²çš„æ“ä½œæµç¨‹ã€‚\n",
        "\n",
        "âš ï¸ä»¥ä¸‹ä»£ç éœ€æ¶ˆè€— 20G+çš„å†…å­˜ï¼Œè¯·ç¡®ä¿åˆ·å‡ºæ¥çš„æœºå™¨RAMæ»¡è¶³è¦æ±‚ã€‚"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yVliGZLL1Asa"
      },
      "source": [
        "## ä¸€ã€ç¯å¢ƒä¸ä»£ç å‡†å¤‡å·¥ä½œ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RAPy82rx1D3h"
      },
      "source": [
        "### 1.1 å®‰è£…ç›¸å…³ä¾èµ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QREF94o6Jbqp"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.30.2\n",
        "!pip install peft==0.3.0\n",
        "!pip install sentencepiece\n",
        "!pip install bitsandbytes\n",
        "!pip install gradio\n",
        "!pip install mdtex2html"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C0fZplUu0w0p"
      },
      "source": [
        "### 1.2 å…‹éš†ç›®å½•å’Œä»£ç "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fmoBCvSJdek"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ymcui/Chinese-LLaMA-Alpaca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck6Q7fmzJeGU"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/airaria/Visual-Chinese-LLaMA-Alpaca"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2bGlZHt1N0T"
      },
      "source": [
        "### 1.3 å®‰è£…VisualCLAä»£ç "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKSX-8bnOwMV"
      },
      "outputs": [],
      "source": [
        "!pip install -e Visual-Chinese-LLaMA-Alpaca/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "plJM844v1VjW"
      },
      "source": [
        "## äºŒã€åˆå¹¶æ¨¡å‹\n",
        "\n",
        "åˆå¹¶æ¨¡å‹è¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼š\n",
        "* ä»åŸç‰ˆLLaMAåˆå¹¶å‡ºChinese-LLaMA-Alpaca-Plus-7Bæ¨¡å‹\n",
        "* ä»Chinese-LLaMA-Alpaca-Plus-7Båˆå¹¶å‡ºVisualCLAæ¨¡å‹"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NAPz3OX91Z9x"
      },
      "source": [
        "### 2.1 åˆå¹¶Chinese-Alpaca-Plus-7Bæ¨¡å‹\n",
        "\n",
        "æ­¤å¤„ä½¿ç”¨çš„æ˜¯ğŸ¤—æ¨¡å‹åº“ä¸­æä¾›çš„åŸºæ¨¡å‹ï¼ˆHFæ ¼å¼ï¼‰\n",
        "- åŸºæ¨¡å‹ï¼š`elinas/llama-7b-hf-transformers-4.29` *ï¼ˆuse at your own riskï¼Œæˆ‘ä»¬æ¯”å¯¹è¿‡SHA256å’Œæ­£ç‰ˆä¸€è‡´ï¼Œä½†ä½ åº”ç¡®ä¿è‡ªå·±æœ‰æƒä½¿ç”¨è¯¥æ¨¡å‹ï¼‰*\n",
        "- LoRAæ¨¡å‹ï¼š'ziqingyang/chinese-llama-plus-lora-7b,ziqingyang/chinese-alpaca-plus-lora-7b'\n",
        "\n",
        "è½¬æ¢å¥½çš„æ¨¡å‹å­˜æ”¾åœ¨`chinese-alpaca-plus-7b`ç›®å½•ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIq_K65JJ9BZ"
      },
      "outputs": [],
      "source": [
        "!python ./Chinese-LLaMA-Alpaca/scripts/merge_llama_with_chinese_lora_low_mem.py \\\n",
        "    --base_model 'elinas/llama-7b-hf-transformers-4.29' \\\n",
        "    --lora_model 'ziqingyang/chinese-llama-plus-lora-7b,ziqingyang/chinese-alpaca-plus-lora-7b' \\\n",
        "    --output_type huggingface \\\n",
        "    --output_dir chinese-alpaca-plus-7b"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-jo4bkn51iWR"
      },
      "source": [
        "### 2.2 åˆå¹¶VisualCLAæ¨¡å‹\n",
        "\n",
        "åŸºäºChinese-Alpaca-Plus-7Bå’ŒCLIP-ViTï¼Œåˆå¹¶å¾—åˆ°æœ€ç»ˆçš„VisualCLAæ¨¡å‹ã€‚\n",
        "\n",
        "è½¬æ¢å¥½çš„æ¨¡å‹å­˜æ”¾åœ¨`visualcla`ç›®å½•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWMofK9bJ_HH"
      },
      "outputs": [],
      "source": [
        "! python Visual-Chinese-LLaMA-Alpaca/scripts/merge_llama_with_visualcla_lora.py \\\n",
        "    --text_model chinese-alpaca-plus-7b \\\n",
        "    --vision_model openai/clip-vit-large-patch14 \\\n",
        "    --lora_model ziqingyang/visualcla-7b-v0.1 \\\n",
        "    --output_dir visualcla"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zzjiXLuj3Kt_"
      },
      "source": [
        "## ä¸‰ã€ æ¨¡å‹æ¨ç†ä¸éƒ¨ç½²\n",
        "\n",
        "åˆå¹¶å®Œæˆåï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©æ˜¯è¿›è¡Œå‘½ä»¤è¡Œçš„æ¨ç†æˆ–å¯åŠ¨Gradio demoè¿›è¡Œå¯è§†åŒ–ä½“éªŒ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dAcpKKuO2-9Y"
      },
      "source": [
        "### 3.1 å‘½ä»¤è¡Œæ¨ç†\n",
        "\n",
        "è¿è¡Œä¸‹é¢çš„å‘½ä»¤å°†å¯åŠ¨äº¤äº’å¼å‘½ä»¤è¡Œç¨‹åºè¿›è¡Œæ¨ç†ã€‚\n",
        "\n",
        "é»˜è®¤è¯»å…¥image_fileæ–‡ä»¶ï¼Œç”¨æˆ·å¯è¾“å…¥å‘æ¨¡å‹æé—®é¢˜æˆ–è¾“å…¥æŒ‡ä»¤ã€‚\n",
        "\n",
        "ä¹Ÿå¯é€šè¿‡change imageå‘½ä»¤æ›´æ¢å›¾ç‰‡ã€‚è¯¦ç»†ä½¿ç”¨è¯´æ˜å¯å‚è§å¯åŠ¨åçš„æç¤ºä¿¡æ¯ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpJp4xz83DUd"
      },
      "outputs": [],
      "source": [
        "!python Visual-Chinese-LLaMA-Alpaca/scripts/inference/inference.py \\\n",
        "    --visualcla_model visualcla \\\n",
        "    --image_file Visual-Chinese-LLaMA-Alpaca/pics/examples/food.jpg \\\n",
        "    --load_in_8bit"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TaPw3Shg1x31"
      },
      "source": [
        "### 3.2 å¯åŠ¨Gradio\n",
        "\n",
        "è¿è¡Œä¸‹é¢çš„å‘½ä»¤å¯åŠ¨Gradio demoã€‚\n",
        "\n",
        "æˆåŠŸå¯åŠ¨åå•å…ƒæ ¼ä¸­å°†æ˜¾ç¤ºurlåœ°å€ã€‚æ‰“å¼€urlåœ°å€å³å¯è®¿é—®demoã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlWoPpz7KOgR"
      },
      "outputs": [],
      "source": [
        "!python Visual-Chinese-LLaMA-Alpaca/scripts/inference/gradio_demo.py --visualcla_model visualcla --load_in_8bit --share"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
